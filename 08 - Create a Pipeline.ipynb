{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# パイプラインを作成する\n",
        "\n",
        "Azure ML SDK を使用してスクリプトベースの実験を実行すると、データの取り込み、モデルのトレーニング、モデルの登録に必要なさまざまな手順を個々に実行できます。ただし、エンタープライズ環境では、機械学習ソリューションの構築に必要な不連続手順のシーケンスは通常、*パイプライン*にカプセル化されます。このパイプラインは、ユーザーからのデマンド、自動構築プロセス、またはスケジュールに従って、ひとつ以上のコンピューティング先で実行できます。\n",
        "\n",
        "このノートブックでは、あらゆる要素をまとめてシンプルなパイプラインを作成し、データを前処理して、モデルのトレーニングと登録を行います。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ワークスペースに接続する\n",
        "\n",
        "作業を開始するには、ワークスペースに接続します。\n",
        "\n",
        "> **注**: Azure サブスクリプションでまだ認証済みのセッションを確立していない場合は、リンクをクリックして認証コードを入力し、Azure にサインインして認証するよう指示されます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import azureml.core\n",
        "from azureml.core import Workspace\n",
        "\n",
        "# 保存された構成ファイルからワークスペースを読み込む\n",
        "ws = Workspace.from_config()\n",
        "print('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## データを準備する\n",
        "\n",
        "パイプラインでは、糖尿病患者の詳細を含むデータセットを使用します。次のセルを実行して、このデータセットを作成します (以前に作成していた場合は、コードが既存のバージョンを検索します)。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azureml.core import Dataset\n",
        "\n",
        "default_ds = ws.get_default_datastore()\n",
        "\n",
        "if 'diabetes dataset' not in ws.datasets:\n",
        "    default_ds.upload_files(files=['./data/diabetes.csv', './data/diabetes2.csv'], # 糖尿病 CSV ファイルを /data にアップロードする\n",
        "                        target_path='diabetes-data/', # データストアのフォルダー パスに入れる\n",
        "                        overwrite=True, # 同じ名前の既存のファイルを置き換える\n",
        "                        show_progress=True)\n",
        "\n",
        "    #データストア上のパスから表形式のデータセットを作成する (しばらく時間がかかる場合があります)\n",
        "    tab_data_set = Dataset.Tabular.from_delimited_files(path=(default_ds, 'diabetes-data/*.csv'))\n",
        "\n",
        "    # 表形式のデータセットを登録する\n",
        "    try:\n",
        "        tab_data_set = tab_data_set.register(workspace=ws, \n",
        "                                name='diabetes dataset',\n",
        "                                description='diabetes data',\n",
        "                                tags = {'format':'CSV'},\n",
        "                                create_new_version=True)\n",
        "        print('Dataset registered.')\n",
        "    except Exception as ex:\n",
        "        print(ex)\n",
        "else:\n",
        "    print('Dataset already registered.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## パイプライン手順のスクリプトを作成する\n",
        "\n",
        "パイプラインはひとつ以上の*手順*で構成されます。Python スクリプトの場合もあれば、データをひとつの場所から別の場所にコピーするデータ転送手順のように特別な手順の場合もあります。各ステップは、独自のコンピューティング コンテキストで実行できます。この演習では、2 つの Python スクリプトの手順を含むシンプルなパイプラインを構築します。ひとつの手順では一部のトレーニング データを前処理し、もうひとつの手順では前処理されたデータを使用してモデルのトレーニングと登録を行います。\n",
        "\n",
        "まず、パイプラインの手順で使用するスクリプト ファイル用のフォルダーを作成しましょう。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "# パイプライン ステップ ファイル用フォルダーを作成する\n",
        "experiment_folder = 'diabetes_pipeline'\n",
        "os.makedirs(experiment_folder, exist_ok=True)\n",
        "\n",
        "print(experiment_folder)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "糖尿病データセットからデータを読み取り、一部のシンプルな前処理を適用してデータが欠落している行を削除し、類似したスケールになるように数値の特徴を正規化する最初のスクリプトを作成しましょう。\n",
        "\n",
        "スクリプトには **--prepped-data** という名前の引数が含まれます。これは、結果的に生じるデータを保存するフォルダーを参照します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile $experiment_folder/prep_diabetes.py\n",
        "# ライブラリをインポートする\n",
        "import os\n",
        "import argparse\n",
        "import pandas as pd\n",
        "from azureml.core import Run\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# パラメーターを取得する\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument(\"--input-data\", type=str, dest='raw_dataset_id', help='raw dataset')\n",
        "parser.add_argument('--prepped-data', type=str, dest='prepped_data', default='prepped_data', help='Folder for results')\n",
        "args = parser.parse_args()\n",
        "save_folder = args.prepped_data\n",
        "\n",
        "# 実験実行コンテキストを取得する\n",
        "run = Run.get_context()\n",
        "\n",
        "# データを読み込む (入力データセットとして渡される)\n",
        "print(\"Loading Data...\")\n",
        "diabetes = run.input_datasets['raw_data'].to_pandas_dataframe()\n",
        "\n",
        "# 生の行数をログに記録する\n",
        "row_count = (len(diabetes))\n",
        "run.log('raw_rows', row_count)\n",
        "\n",
        "# Null 値を削除する\n",
        "diabetes = diabetes.dropna()\n",
        "\n",
        "# 数値列を正規化する\n",
        "scaler = MinMaxScaler()\n",
        "num_cols = ['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree']\n",
        "diabetes[num_cols] = scaler.fit_transform(diabetes[num_cols])\n",
        "\n",
        "# 処理済みの行をログする\n",
        "row_count = (len(diabetes))\n",
        "run.log('processed_rows', row_count)\n",
        "\n",
        "# 準備されたデータを保存する\n",
        "print(\"Saving Data...\")\n",
        "os.makedirs(save_folder, exist_ok=True)\n",
        "save_path = os.path.join(save_folder,'data.csv')\n",
        "diabetes.to_csv(save_path, index=False, header=True)\n",
        "\n",
        "# 実行を終了する\n",
        "run.complete()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "これで、モデルをトレーニングする 2 番目の手順のスクリプトを作成できます。スクリプトには **--training-folder** という名前の引数が含まれます。これは、準備済みのデータが以前の手順で保存されたフォルダーを参照します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile $experiment_folder/train_diabetes.py\n",
        "# ライブラリをインポートする\n",
        "from azureml.core import Run, Model\n",
        "import argparse\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import roc_curve\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# パラメーターを取得する\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument(\"--training-folder\", type=str, dest='training_folder', help='training data folder')\n",
        "args = parser.parse_args()\n",
        "training_folder = args.training_folder\n",
        "\n",
        "# 実験実行コンテキストを取得する\n",
        "run = Run.get_context()\n",
        "\n",
        "# トレーニング フォルダーで準備済みのデータ ファイルを読み込む\n",
        "print(\"Loading Data...\")\n",
        "file_path = os.path.join(training_folder,'data.csv')\n",
        "diabetes = pd.read_csv(file_path)\n",
        "\n",
        "# 特徴とラベルを分離する\n",
        "X, y = diabetes[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']].values, diabetes['Diabetic'].values\n",
        "\n",
        "# データをトレーニング セットとテスト セットに分割する\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
        "\n",
        "# デシジョン ツリー モデルをトレーニングする\n",
        "print('Training a decision tree model...')\n",
        "model = DecisionTreeClassifier().fit(X_train, y_train)\n",
        "\n",
        "# 精度を計算する\n",
        "y_hat = model.predict(X_test)\n",
        "acc = np.average(y_hat == y_test)\n",
        "print('Accuracy:', acc)\n",
        "run.log('Accuracy', np.float(acc))\n",
        "\n",
        "# AUC を計算する\n",
        "y_scores = model.predict_proba(X_test)\n",
        "auc = roc_auc_score(y_test,y_scores[:,1])\n",
        "print('AUC: ' + str(auc))\n",
        "run.log('AUC', np.float(auc))\n",
        "\n",
        "# ROC 曲線をプロットする\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_scores[:,1])\n",
        "fig = plt.figure(figsize=(6, 4))\n",
        "# 対角 50% ラインをプロットする\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "# モデルによって達成された FPR と TPR をプロットする\n",
        "plt.plot(fpr, tpr)\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve')\n",
        "run.log_image(name = \"ROC\", plot = fig)\n",
        "plt.show()\n",
        "\n",
        "# トレーニング済モデルを出力フォルダーに保存する。\n",
        "print(\"Saving model...\")\n",
        "os.makedirs('outputs', exist_ok=True)\n",
        "model_file = os.path.join('outputs', 'diabetes_model.pkl')\n",
        "joblib.dump(value=model, filename=model_file)\n",
        "\n",
        "# モデルを登録する\n",
        "print('Registering model...')\n",
        "Model.register(workspace=run.experiment.workspace,\n",
        "               model_path = model_file,\n",
        "               model_name = 'diabetes_model',\n",
        "               tags={'Training context':'Pipeline'},\n",
        "               properties={'AUC': np.float(auc), 'Accuracy': np.float(acc)})\n",
        "\n",
        "\n",
        "run.complete()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## パイプライン手順用のコンピューティング環境を準備する\n",
        "\n",
        "この演習では、両方のステップで同じコンピューティングを使用しますが、各ステップは独立して実行されることを認識することが重要です。必要に応じて、各ステップに異なるコンピューティング コンテキストを指定できます。\n",
        "\n",
        "最初に、前のラボで作成したコンピューティング ターゲットを取得します (存在しない場合は作成されます)。\n",
        "\n",
        "> **重要**: 実行する前に、以下のコードで *your-compute-cluster* をコンピューティング クラスターの名前に変更してください。クラスター名は、長さが 2 〜 16 文字のグローバルに一意の名前である必要があります。英字、数字、- の文字が有効です。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azureml.core.compute import ComputeTarget, AmlCompute\n",
        "from azureml.core.compute_target import ComputeTargetException\n",
        "\n",
        "cluster_name = \"your-compute-cluster\"\n",
        "\n",
        "try:\n",
        "    # 既存のコンピューティング先を確認する\n",
        "    pipeline_cluster = ComputeTarget(workspace=ws, name=cluster_name)\n",
        "    print('Found existing cluster, use it.')\n",
        "except ComputeTargetException:\n",
        "    # まだ存在しない場合は、作成します\n",
        "    try:\n",
        "        compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_DS11_V2', max_nodes=2)\n",
        "        pipeline_cluster = ComputeTarget.create(ws, cluster_name, compute_config)\n",
        "        pipeline_cluster.wait_for_completion(show_output=True)\n",
        "    except Exception as ex:\n",
        "        print(ex)\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "このコンピューティングには、必要なパッケージの依存関係がインストールされた Python 環境が必要となるため、実行構成を作成する必要があります。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azureml.core import Environment\n",
        "from azureml.core.conda_dependencies import CondaDependencies\n",
        "from azureml.core.runconfig import RunConfiguration\n",
        "\n",
        "# 実験用 Python 環境を作成する\n",
        "diabetes_env = Environment(\"diabetes-pipeline-env\")\n",
        "diabetes_env.python.user_managed_dependencies = False # 依存関係を Azure ML に管理させる\n",
        "diabetes_env.docker.enabled = True # ドッカー コンテナーを使用する\n",
        "\n",
        "# パッケージの依存関係のセットを作成する\n",
        "diabetes_packages = CondaDependencies.create(conda_packages=['scikit-learn','ipykernel','matplotlib','pandas','pip'],\n",
        "                                             pip_packages=['azureml-defaults','azureml-dataprep[pandas]','pyarrow'])\n",
        "\n",
        "# 環境に依存関係を追加する\n",
        "diabetes_env.python.conda_dependencies = diabetes_packages\n",
        "\n",
        "# 環境を登録する \n",
        "diabetes_env.register(workspace=ws)\n",
        "registered_env = Environment.get(ws, 'diabetes-pipeline-env')\n",
        "\n",
        "# パイプライン用の新しい runconfig オブジェクトを作成する\n",
        "pipeline_run_config = RunConfiguration()\n",
        "\n",
        "# 上記で作成したコンピューティングを使用します。 \n",
        "pipeline_run_config.target = pipeline_cluster\n",
        "\n",
        "# 環境を実行構成に割り当てる\n",
        "pipeline_run_config.environment = registered_env\n",
        "\n",
        "print (\"Run configuration created.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## パイプラインを作成して実行する\n",
        "\n",
        "これで、パイプラインを作成および実行する準備が整いました。\n",
        "\n",
        "まず、パイプラインの手順と、パイプライン間で渡す必要があるデータ参照を定義する必要があります。この場合、最初の手順では、2 番目の手順で読み取ることができるフォルダーに準備済みのデータを書き込む必要があります。これらの手順はリモート コンピューティングで実行されるため (実際には、それぞれ異なるコンピューティングで実行できます)、ワークスペース内のデータストア内の場所に、フォルダー パスをデータ参照として渡す必要があります。**PipelineData** オブジェクトは、パイプラインの手順間で渡すことができる中間ストレージの場所で使われる特殊な種類のデータ参照なので、1 つ作成して、最初の手順の出力と 2 番目の手順の入力として使用します。また、コードがデータ参照によって参照されるデータストアの場所にアクセスできるように、スクリプト引数として渡す必要があることに注意してください。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azureml.pipeline.core import PipelineData\n",
        "from azureml.pipeline.steps import PythonScriptStep\n",
        "\n",
        "# トレーニング データセットを取得する\n",
        "diabetes_ds = ws.datasets.get(\"diabetes dataset\")\n",
        "\n",
        "# モデル フォルダー用パイプラインデータ (一時データ参照) を作成する\n",
        "prepped_data_folder = PipelineData(\"prepped_data_folder\", datastore=ws.get_default_datastore())\n",
        "\n",
        "# 手順 1: データ準備スクリプトを実行する\n",
        "prep_step = PythonScriptStep(name = \"Prepare Data\",\n",
        "                                source_directory = experiment_folder,\n",
        "                                script_name = \"prep_diabetes.py\",\n",
        "                                arguments = ['--input-data', diabetes_ds.as_named_input('raw_data'),\n",
        "                                             '--prepped-data', prepped_data_folder],\n",
        "                                outputs=[prepped_data_folder],\n",
        "                                compute_target = pipeline_cluster,\n",
        "                                runconfig = pipeline_run_config,\n",
        "                                allow_reuse = True)\n",
        "\n",
        "# 手順 2: トレーニング スクリプトを実行する\n",
        "train_step = PythonScriptStep(name = \"Train and Register Model\",\n",
        "                                source_directory = experiment_folder,\n",
        "                                script_name = \"train_diabetes.py\",\n",
        "                                arguments = ['--training-folder', prepped_data_folder],\n",
        "                                inputs=[prepped_data_folder],\n",
        "                                compute_target = pipeline_cluster,\n",
        "                                runconfig = pipeline_run_config,\n",
        "                                allow_reuse = True)\n",
        "\n",
        "print(\"Pipeline steps defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "これで、定義した手順からパイプラインを構築し、実験として実行できます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "from azureml.core import Experiment\n",
        "from azureml.pipeline.core import Pipeline\n",
        "from azureml.widgets import RunDetails\n",
        "\n",
        "# パイプラインを構築する\n",
        "pipeline_steps = [prep_step, train_step]\n",
        "pipeline = Pipeline(workspace=ws, steps=pipeline_steps)\n",
        "print(\"Pipeline is built.\")\n",
        "\n",
        "# 実験を作成してパイプラインを実行する\n",
        "experiment = Experiment(workspace=ws, name = 'mslearn-diabetes-pipeline')\n",
        "pipeline_run = experiment.submit(pipeline, regenerate_outputs=True)\n",
        "print(\"Pipeline submitted for execution.\")\n",
        "RunDetails(pipeline_run).show()\n",
        "pipeline_run.wait_for_completion(show_output=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "実行中のパイプライン実験のグラフィカル表示がウィジェットに表示されます。ページの右上にあるカーネル インジケータに注目してください。**&#9899;** から **&#9711;** に変わると、コードの実行が終了します。[Azure Machine Learning Studio](https://ml.azure.com) の**実験**ページでパイプラインの実行を監視することもできます。\n",
        "\n",
        "パイプラインが終了すると、子実行により記録された指標を確認できます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for run in pipeline_run.get_children():\n",
        "    print(run.name, ':')\n",
        "    metrics = run.get_metrics()\n",
        "    for metric_name in metrics:\n",
        "        print('\\t',metric_name, \":\", metrics[metric_name])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "パイプラインが成功すると、新しいモデルを*トレーニング コンテキスト* タグに登録して、パイプラインでトレーニングされたことを示す必要があります。これを確認するには、次のコードを実行します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azureml.core import Model\n",
        "\n",
        "for model in Model.list(ws):\n",
        "    print(model.name, 'version:', model.version)\n",
        "    for tag_name in model.tags:\n",
        "        tag = model.tags[tag_name]\n",
        "        print ('\\t',tag_name, ':', tag)\n",
        "    for prop_name in model.properties:\n",
        "        prop = model.properties[prop_name]\n",
        "        print ('\\t',prop_name, ':', prop)\n",
        "    print('\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## パイプラインを発行する\n",
        "\n",
        "パイプラインを作成してテストした後、REST サービスとして公開できます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 実行からパイプラインを発行する\n",
        "published_pipeline = pipeline_run.publish_pipeline(\n",
        "    name=\"diabetes-training-pipeline\", description=\"Trains diabetes model\", version=\"1.0\")\n",
        "\n",
        "published_pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "公開されたパイプラインにはエンドポイントがあり、[Azure Machine Learning Studio](https://ml.azure.com) の**エンドポイント** ページ (**パイプライン エンドポイント** タブ) に表示されます。また、公開されたパイプライン オブジェクトのプロパティとして URI を見つけることもできます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rest_endpoint = published_pipeline.endpoint\n",
        "print(rest_endpoint)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## パイプライン エンドポイントを呼び出す\n",
        "\n",
        "エンドポイントを使用するには、クライアント アプリケーションが HTTP 経由で REST 呼び出しを行う必要があります。この要求は認証される必要があるため、Authorization ヘッダーが必要です。実際のアプリケーションには、認証に使用するサービス プリンシパルが必要ですが、これをテストするには、現在の接続から Azure ワークスペースへの Authorization ヘッダーを使用します。これは、次のコードを使用して取得できます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azureml.core.authentication import InteractiveLoginAuthentication\n",
        "\n",
        "interactive_auth = InteractiveLoginAuthentication()\n",
        "auth_header = interactive_auth.get_authentication_header()\n",
        "print(\"Authentication header ready.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "これで、REST インターフェイスを呼び出す準備ができました。パイプラインは非同期で実行されるため、識別子を取得します。実行中のパイプライン実験を追跡するために使用できます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "experiment_name = 'mslearn-diabetes-pipeline'\n",
        "\n",
        "rest_endpoint = published_pipeline.endpoint\n",
        "response = requests.post(rest_endpoint, \n",
        "                         headers=auth_header, \n",
        "                         json={\"ExperimentName\": experiment_name})\n",
        "run_id = response.json()[\"Id\"]\n",
        "run_id"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "実行 ID を持っているので、その ID を使用し、実行が完了するのを待ちます。\n",
        "\n",
        "> **注**: 各ステップは出力の再利用を許可するように構成されているため、パイプラインは迅速に完了するはずです。これは、主に利便性とこのコースの時間を節約するために行われました。実際には、データが変更された場合に備えて、最初のステップを毎回実行し、ステップ 1 の出力が変更された場合にのみ後続のステップをトリガーする必要があります。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azureml.pipeline.core.run import PipelineRun\n",
        "\n",
        "published_pipeline_run = PipelineRun(ws.experiments[experiment_name], run_id)\n",
        "pipeline_run.wait_for_completion(show_output=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## パイプラインをスケジュールする\n",
        "\n",
        "たとえば、糖尿病患者の診療所が毎週新しいデータを収集し、データセットに追加したとします。パイプラインを毎週実行して、新しいデータでモデルを再トレーニングできます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azureml.pipeline.core import ScheduleRecurrence, Schedule\n",
        "\n",
        "# 毎週月曜日の 00:00 UTC にパイプラインを送信する\n",
        "recurrence = ScheduleRecurrence(frequency=\"Week\", interval=1, week_days=[\"Monday\"], time_of_day=\"00:00\")\n",
        "weekly_schedule = Schedule.create(ws, name=\"weekly-diabetes-training\", \n",
        "                                  description=\"Based on time\",\n",
        "                                  pipeline_id=published_pipeline.id, \n",
        "                                  experiment_name='mslearn-diabetes-pipeline', \n",
        "                                  recurrence=recurrence)\n",
        "print('Pipeline scheduled.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "以下のように、ワークスペースで定義されているスケジュールを取得できます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "schedules = Schedule.list(ws)\n",
        "schedules"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "次のように最新の実行を確認できます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pipeline_experiment = ws.experiments.get('mslearn-diabetes-pipeline')\n",
        "latest_run = list(pipeline_experiment.get_runs())[0]\n",
        "\n",
        "latest_run.get_details()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "これは、原理を示すために設計された簡単な例です。実際には、より高度なロジックをパイプライン ステップに組み込むことができます。たとえば、一部のテスト データに対してモデルを評価して AUC や精度などのパフォーマンス メトリックを計算し、以前に登録したモデルのバージョンのメトリックと比較して、パフォーマンスが向上した場合のみ新しいモデルを登録します。\n",
        "\n",
        "[Azure DevOps 用 Azure Machine Learning 拡張機能](https://marketplace.visualstudio.com/items?itemName=ms-air-aiagility.vss-services-azureml)を使用して、Azure ML パイプラインと Azure DevOps パイプラインを組み合わせて (そう、同じ名前委の場合は混乱*します*)、モデルの再トレーニングを*継続的統合/継続的デプロイ (CI/CD) プロセス*に統合します。たとえば、Azure DevOps *ビルド* パイプラインを使用して、モデルをトレーニングおよび登録する Azure ML パイプラインをトリガーし、モデルが登録されると、モデルを Web サービスとしてデプロイする Azure Devops *リリース* パイプラインとモデルを使用するアプリケーションまたはサービスをトリガーできます。"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.6 - AzureML",
      "language": "python",
      "name": "python3-azureml"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}